{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Perform this activity under GPU runtime i.e., while opening the colab notebook there is an option of Runtime there under that it has change runtime type a box will appear from there click on drop down menu and check the GPU instead of None, hence it will lead to faster computation and will take some time to get computer"
      ],
      "metadata": {
        "id": "FLThSK9CniLd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhEhh67mZYbO"
      },
      "outputs": [],
      "source": [
        "# these are some of the modules\n",
        "import tensorflow as tf # tensorflow is the module used in deep learning for complex computing\n",
        "import keras # keras is the API which works on tensorflow to make accessibility of tensorflow easier\n",
        "from keras.datasets import mnist # code to import mnist data from keras library\n",
        "# not downloading and mounting because it a heavy file\n",
        "import matplotlib.pyplot as plt # used to plot images,graphs\n",
        "import numpy as np # used for mathematical calculations in 2d arrays\n",
        "from keras import models # used to get the sequential flow layer for neural networks\n",
        "from keras.layers import Dense,MaxPooling2D,Flatten,Conv2D,Dropout\n",
        "# These all are neural layers  \n",
        "# Dense layer is typical artificial neural networks\n",
        "# MaxPooling2D layer is used to reduce the complexity of image\n",
        "# Flatten is used to convert 2d image into 1d image ie., in an array form\n",
        "# Conv2d is used in image processing and its too a neural layer\n",
        "# Dropout layer is used in model so it does not do overfitting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the data from keras and storing accordingly in train and test\n",
        "(x_train,y_train), (x_test,y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-k4IyHRZko9",
        "outputId": "5f57e5c3-15e8-4d42-f6eb-5d4c1607ae51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# an example how to look onto image from img data\n",
        "plt.imshow(x_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mzyA4C3qaUxK",
        "outputId": "86250699-cc32-4abf-9d4c-26373f46c0da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8b3a2bc190>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping the train and test file of x_feature into 3D from 2D\n",
        "x_train = np.reshape(x_train,(-1,28,28,1))\n",
        "x_test = np.reshape(x_test,(-1,28,28,1))"
      ],
      "metadata": {
        "id": "VQSNhrNNbE8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of training datas\n",
        "x_train.shape,x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhJau3kMbdMn",
        "outputId": "8527ca84-578b-4587-d47e-aae5e12af6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (10000, 28, 28, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encoding the y_labels of train and test\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "OwTeYXGYbesn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# since the no. possible is from 0 to 9 so it has been encodded in such a way\n",
        "# that if the number is 5 then on the 6th index it will make it 1 and rest 0\n",
        "# that is one hot encoding\n",
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGaPuJ46l5Fg",
        "outputId": "222c82f0-6f50-4fc7-e566-95da62cf6df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of training labels of y\n",
        "y_train.shape,y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h55GEeiFbnwg",
        "outputId": "c765f201-33e9-44b3-bca6-3e9ffd43361c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 10), (10000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# choosing our flow of neural netowrk ie., in sequential order\n",
        "new_model = keras.Sequential()"
      ],
      "metadata": {
        "id": "BNa5QAnPbp5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# these are the bunch of neual layers making it a neural networks with \n",
        "# multiple hyperparameters\n",
        "conv1 = Conv2D(32, kernel_size = (5,5), strides = (1,1), padding = 'same', data_format = 'channels_last', activation = 'relu', use_bias = True, input_shape = (28,28,1))\n",
        "max_pool1 = MaxPooling2D(pool_size = (2,2), strides = (1,1), padding = 'same', data_format = 'channels_last')\n",
        "conv2 = Conv2D(64, kernel_size = (5,5), strides = (1,1), padding = 'same', data_format = 'channels_last', activation = 'relu', use_bias = True) \n",
        "max_pool2 = MaxPooling2D(pool_size = (2,2), strides = (1,1), padding = 'same', data_format = 'channels_last')\n",
        "flat_layer = Flatten()\n",
        "dense_layer = Dense(1024, activation = 'relu', use_bias = True)\n",
        "drop_layer = Dropout(0.4)\n",
        "output_layer = Dense(10, activation = 'softmax', use_bias = True)"
      ],
      "metadata": {
        "id": "8fK5N6kkcCXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding the neural layers into sequential model for sequential flow\n",
        "new_model.add(conv1)\n",
        "new_model.add(max_pool1)\n",
        "new_model.add(conv2)\n",
        "new_model.add(max_pool2)\n",
        "new_model.add(flat_layer)\n",
        "new_model.add(dense_layer)\n",
        "new_model.add(drop_layer)\n",
        "new_model.add(output_layer)"
      ],
      "metadata": {
        "id": "pnm8hqpjcbde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# looking the model summary with with total parameters to be trained is 51,443,594\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLvEM-DzdT_y",
        "outputId": "efcf1fc8-0842-4451-9334-827484cae50b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 32)        832       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 28, 28, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 28, 28, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 50176)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              51381248  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,443,594\n",
            "Trainable params: 51,443,594\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model \n",
        "new_model.compile(optimizer = 'rmsprop',loss = keras.losses.categorical_crossentropy,metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "ST2B_YrIcd0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting the model with training data\n",
        "new_model.fit(x_train,y_train,batch_size = 50,epochs = 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80cxhT8gcxvb",
        "outputId": "c26e01cb-a44b-4cca-a24e-98f703355de3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1200/1200 [==============================] - 45s 28ms/step - loss: 2.2673 - accuracy: 0.9209\n",
            "Epoch 2/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.1571 - accuracy: 0.9637\n",
            "Epoch 3/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.1401 - accuracy: 0.9685\n",
            "Epoch 4/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.1622 - accuracy: 0.9683\n",
            "Epoch 5/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.1818 - accuracy: 0.9661\n",
            "Epoch 6/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.2026 - accuracy: 0.9629\n",
            "Epoch 7/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.2104 - accuracy: 0.9632\n",
            "Epoch 8/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.2345 - accuracy: 0.9602\n",
            "Epoch 9/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.2571 - accuracy: 0.9589\n",
            "Epoch 10/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.2833 - accuracy: 0.9566\n",
            "Epoch 11/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.2737 - accuracy: 0.9561\n",
            "Epoch 12/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.2953 - accuracy: 0.9550\n",
            "Epoch 13/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.3385 - accuracy: 0.9513\n",
            "Epoch 14/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.3562 - accuracy: 0.9458\n",
            "Epoch 15/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.3598 - accuracy: 0.9489\n",
            "Epoch 16/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.3617 - accuracy: 0.9447\n",
            "Epoch 17/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.4145 - accuracy: 0.9383\n",
            "Epoch 18/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.4290 - accuracy: 0.9372\n",
            "Epoch 19/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.4192 - accuracy: 0.9357\n",
            "Epoch 20/20\n",
            "1200/1200 [==============================] - 33s 28ms/step - loss: 0.4695 - accuracy: 0.9306\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8b301885d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using model for testing and getting accuracy of 97%\n",
        "new_model.evaluate(x_test,y_test,batch_size = 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT0iU9UxdgYn",
        "outputId": "2bc806e9-3208-4063-9f1e-d0ecff4d12a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3285 - accuracy: 0.9666\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.32848820090293884, 0.9666000008583069]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# doing some manual testing\n",
        "def cal(ip):\n",
        "  testing_img = x_test[ip]\n",
        "  testing_img2 = testing_img.reshape(-1,28,28,1)\n",
        "  pred = new_model.predict(testing_img2)\n",
        "  class_id = np.argmax(pred[0])\n",
        "  print(\"Predicted image value :\",class_id)"
      ],
      "metadata": {
        "id": "iFZCznUJjnrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ip = int(input(\"Enter a value from 0 to 9999 :\"))\n",
        "cal(ip)\n",
        "dummy = np.reshape(x_test[ip],(28,28))\n",
        "plt.imshow(dummy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "_E3mb-1aekwm",
        "outputId": "44a74008-45b7-466d-d9ec-d2432c1b8b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a value from 0 to 9999 :9000\n",
            "Predicted image value : 7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8abc147210>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W84EOsGRhOqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ysim-ttzjUL1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}